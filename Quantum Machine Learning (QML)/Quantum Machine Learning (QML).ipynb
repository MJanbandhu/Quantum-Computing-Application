{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00722429",
   "metadata": {},
   "source": [
    "# Quantum Machine Learning (QML) — Full end-to-end workflow\n",
    "\n",
    "Goal: Use a variational quantum circuit (a small QML model) to classify Iris flower species.\n",
    "This follows your ML steps with the quantum-specific steps (encoding, quantum circuit, hybrid training) included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c18a0",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "\n",
    "Use a quantum machine learning model (variational quantum circuit) to classify Iris flowers (Setosa vs Versicolor). For demonstration we will convert the multiclass Iris dataset to a binary problem (class 0 vs class 1) so training on a small QPU/simulator is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9940677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e0865c1",
   "metadata": {},
   "source": [
    "# Import basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn for classical preprocessing and evaluation\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# PennyLane for quantum circuits\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a2ba1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris(as_frame=True)\n",
    "data = iris.frame.copy()\n",
    "data['target'] = iris.target\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc17fd3",
   "metadata": {},
   "source": [
    "# Domain analysis\n",
    "\n",
    "The Iris dataset records sepal length, sepal width, petal length, petal width for three species. For QML demonstration we will convert this into a binary classification problem: Setosa (target 0) vs Versicolor (target 1). This keeps the circuit and training simple while illustrating QML steps. In real applications you can extend to multiclass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e0dba",
   "metadata": {},
   "source": [
    "# Basic checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", data.shape)\n",
    "print(\"Columns:\", data.columns.tolist())\n",
    "print(data.info())\n",
    "print(data.describe().T)\n",
    "print(\"Missing values:\\n\", data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7f34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c974969f",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data.loc[data['target'].isin([0,1]), ['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)','target']],\n",
    "             hue='target')\n",
    "plt.show()\n",
    "\n",
    "# Quick correlation heatmap\n",
    "sns.heatmap(data.iloc[:, :4].corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8d351",
   "metadata": {},
   "source": [
    "Insights: Petal length/width are very separable for Setosa vs Versicolor — good features for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25970313",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f16715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter dataset to classes 0 and 1.\n",
    "\n",
    "#Use PCA to reduce dimensions to match available qubits (e.g., 2 features → 2 qubits).\n",
    "# Quantum circuits with few qubits are easier to simulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c031da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to classes 0 and 1\n",
    "df = data[data['target'].isin([0,1])].copy()\n",
    "X = df.iloc[:, :4].values\n",
    "y = df['target'].values\n",
    "\n",
    "# Encode labels (already 0/1) - keep as-is\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50400f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ffb4812",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features to [0, 1] (helpful for angle/amplitude embedding).\n",
    "\n",
    "# Use PCA to reduce to 2 features (2 qubits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reduce to 2 components for two qubits\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a5c8b",
   "metadata": {},
   "source": [
    "### Quantum-specific step — choose encoding and device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42401468",
   "metadata": {},
   "source": [
    "#### We will use angle encoding (map each feature to a rotation angle) and a small variational ansatz with entanglement. Use PennyLane default.qubit simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24eff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71388de4",
   "metadata": {},
   "source": [
    "# Model building — define variational circuit and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb84e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An AngleEmbedding to encode classical features into rotation angles on qubits.\n",
    "\n",
    "# A variational layer (parametrized rotations + entangling gates).\n",
    "\n",
    "# Measurement returns expectation of PauliZ on first qubit; map expectation to class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of variational layers\n",
    "n_layers = 3\n",
    "\n",
    "def variational_ansatz(weights, x):\n",
    "    # Encode classical data x (length 2) into qubits with AngleEmbedding\n",
    "    qml.AngleEmbedding(x, wires=range(n_qubits), rotation='Y')\n",
    "    # Variational layers: layers of single-qubit rotations and entanglers\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "\n",
    "@qml.qnode(dev, interface='autograd')\n",
    "def qnode(weights, x):\n",
    "    variational_ansatz(weights, x)\n",
    "    # Measure expectation of PauliZ on wire 0\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need initial weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape for StronglyEntanglingLayers: (n_layers, n_wires, 3)\n",
    "weights_shape = (n_layers, n_qubits, 3)\n",
    "weights = pnp.random.normal(scale=0.1, size=weights_shape, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc368e9",
   "metadata": {},
   "source": [
    "#### Define helper to map expectation to class probability/label:\n",
    "\n",
    "* Expectation is in [-1, 1]. Map to probability via (1 - exp)/2 or a sigmoid on expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_to_prob(expval):\n",
    "    # Map expectation [-1,1] to probability of class 1\n",
    "    return (1 - expval) / 2.0\n",
    "\n",
    "def predict_label(weights, x):\n",
    "    expval = qnode(weights, x)\n",
    "    prob1 = exp_to_prob(expval)\n",
    "    return 1 if prob1 >= 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc22843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd7cc340",
   "metadata": {},
   "source": [
    "# Training — hybrid quantum-classical training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a7730",
   "metadata": {},
   "source": [
    "We define a mean squared error loss using expectation mapped to labels and optimize weights using an optimizer (PennyLane Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b77f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, X, Y):\n",
    "    preds = [exp_to_prob(qnode(weights, x)) for x in X]\n",
    "    preds = pnp.array(preds)\n",
    "    Y = pnp.array(Y, dtype=float)\n",
    "    return pnp.mean((preds - Y)**2)\n",
    "\n",
    "opt = qml.AdamOptimizer(stepsize=0.1)\n",
    "epochs = 40\n",
    "batch_size = 8\n",
    "\n",
    "weights_opt = weights.copy()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Mini-batch SGD\n",
    "    perm = np.random.permutation(len(X_train))\n",
    "    X_shuffled = X_train[perm]\n",
    "    Y_shuffled = y_train[perm]\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_shuffled[i:i+batch_size]\n",
    "        Y_batch = Y_shuffled[i:i+batch_size]\n",
    "        weights_opt = opt.step(lambda w: cost(w, X_batch, Y_batch), weights_opt)\n",
    "\n",
    "    # training loss\n",
    "    train_loss = cost(weights_opt, X_train, y_train)\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:2d} — Train loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5046fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ab8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f82154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b509f42",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161affa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [predict_label(weights_opt, x) for x in X_test]\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddaad4a",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33682a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# Optional: show heatmap for confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe20bf",
   "metadata": {},
   "source": [
    "Interpretation: Compare accuracy with a classical baseline (e.g., logistic regression) to see whether the QML approach performs comparably on this small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90329f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical baseline quick test:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_clf = clf.predict(X_test)\n",
    "print(\"Classical logistic regression accuracy:\", accuracy_score(y_test, y_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6be57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59c1bcd6",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "* The pipeline shows a full ML workflow adapted for QML:\n",
    "\n",
    "    * standard data steps (EDA, preprocessing, splitting)\n",
    "\n",
    "    * quantum-specific steps (encoding → quantum circuit → hybrid training)\n",
    "\n",
    "* For small toy datasets like Iris, QML can match classical baselines in some experiments, but the main value of QML will appear for tasks or models where quantum advantages apply.\n",
    "\n",
    "* Important hyperparameters: number of qubits, encoding method, circuit depth (number of layers), optimizer and training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280aa1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108b462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357fe77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7634ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full script (compact)\n",
    "\n",
    "# Below is a single script that bundles the above steps — copy-paste and run if PennyLane and scikit-learn are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd3c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qml_iris_example.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "# Load data\n",
    "iris = load_iris(as_frame=True)\n",
    "data = iris.frame.copy()\n",
    "data['target'] = iris.target\n",
    "\n",
    "# Binary classification: class 0 vs 1\n",
    "df = data[data['target'].isin([0,1])].copy()\n",
    "X = df.iloc[:, :4].values\n",
    "y = df['target'].values\n",
    "\n",
    "# Preprocess\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Quantum setup\n",
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "n_layers = 3\n",
    "\n",
    "def variational_ansatz(weights, x):\n",
    "    qml.AngleEmbedding(x, wires=range(n_qubits), rotation='Y')\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "\n",
    "@qml.qnode(dev, interface='autograd')\n",
    "def qnode(weights, x):\n",
    "    variational_ansatz(weights, x)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "weights_shape = (n_layers, n_qubits, 3)\n",
    "weights = pnp.random.normal(scale=0.1, size=weights_shape, requires_grad=True)\n",
    "\n",
    "def exp_to_prob(expval):\n",
    "    return (1 - expval) / 2.0\n",
    "\n",
    "def predict_label(weights, x):\n",
    "    expval = qnode(weights, x)\n",
    "    prob1 = exp_to_prob(expval)\n",
    "    return 1 if prob1 >= 0.5 else 0\n",
    "\n",
    "def cost(weights, X, Y):\n",
    "    preds = [exp_to_prob(qnode(weights, x)) for x in X]\n",
    "    preds = pnp.array(preds)\n",
    "    Y = pnp.array(Y, dtype=float)\n",
    "    return pnp.mean((preds - Y)**2)\n",
    "\n",
    "opt = qml.AdamOptimizer(stepsize=0.1)\n",
    "epochs = 40\n",
    "batch_size = 8\n",
    "weights_opt = weights.copy()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    perm = np.random.permutation(len(X_train))\n",
    "    X_shuffled = X_train[perm]\n",
    "    Y_shuffled = y_train[perm]\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_shuffled[i:i+batch_size]\n",
    "        Y_batch = Y_shuffled[i:i+batch_size]\n",
    "        weights_opt = opt.step(lambda w: cost(w, X_batch, Y_batch), weights_opt)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:2d} — Train loss: {cost(weights_opt, X_train, y_train):.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "y_pred = [predict_label(weights_opt, x) for x in X_test]\n",
    "print(\"QML Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "# Classical baseline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_cl = clf.predict(X_test)\n",
    "print(\"Classical logistic regression accuracy:\", accuracy_score(y_test, y_cl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
